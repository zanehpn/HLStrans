[
  {
    "input": "This is an unsynthesizable C code:\nslow code Version:\n\n```cpp\nunsigned long add_rur(unsigned n) {\n    if (n == 0) return 1;\n    return n * add_rur(n - 1);\n}\n```\nWe want to turn it into synthesizable C code. Just give me the HLS code.",
    "app": "add_cur"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\n#define NPOINTS 64\n#define ORDER 32\n\n\nvoid latnrm(float data[NPOINTS], float outa[NPOINTS], float coefficient[ORDER*2],\n            float internal_state[ORDER+1])\n\n{\n    int i;\n    int j;\n\n    float left, right, top;\n    float bottom = 0;\n    float sum; \n    for (i = 0; i < NPOINTS; i++)\n    {\n        top = data[i];\n        for (j = 1; j < ORDER; j++)\n        {\n            left = top;\n            right = internal_state[j];\n            internal_state[j] = bottom;\n            top = coefficient[j - 1] * left - coefficient[j] * right;\n            bottom = coefficient[j - 1] * right + coefficient[j] * left;\n        }\n        internal_state[ORDER] = bottom;\n        internal_state[ORDER + 1] = top;\n        sum = 0.0;\n        for (j = 0; j < ORDER; j++)\n        {\n            sum += internal_state[j] * coefficient[j + ORDER];\n        }\n        outa[i] = sum;\n    }\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "latnrm"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\n#include <stdio.h>\n#include <iostream>\n#include <fstream>\n#include <cstdlib>\n#include <ap_fixed.h>\n#include <hls_math.h>\n#include <stdlib.h>\n#include <cstdint>\n\ntypedef ap_fixed<16, 5> fixed_t;\n\n\n#define B   4      \n#define N   100     \n#define dk  128     \n#define dv  128     \nusing namespace std;\n\n\nvoid softmax(float matrix[B][N][N]) {\n    for (int b = 0; b < B; ++b) {\n        for (int i = 0; i < N; ++i) {\n            float max_val = matrix[b][i][0];\n            for (int j = 1; j < N; ++j) {\n                if (matrix[b][i][j] > max_val) {\n                    max_val = matrix[b][i][j];\n                }\n            }\n\n            float sum = 0;\n            for (int j = 0; j < N; ++j) {\n                matrix[b][i][j] = exp(matrix[b][i][j] - max_val);\n                sum += matrix[b][i][j];\n            }\n\n            for (int j = 0; j < N; ++j) {\n                matrix[b][i][j] /= sum;\n            }\n        }\n    }\n}\n\nvoid compute_attention_HLS(fixed_t Q[B][N][dk], fixed_t K[B][N][dk], fixed_t V[B][N][dv], fixed_t Output[B][N][dv]) {\n    float attention[B][N][N];\n    float scale = 1.0 / sqrt((float)dk);\n\n    \n    for (int b = 0; b < B; ++b) {\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < N; ++j) {\n                float sum = 0;\n                for (int k = 0; k < dk; ++k) {\n                    sum += Q[b][i][k].to_float() * K[b][j][k].to_float();\n                }\n                attention[b][i][j] = sum * scale;\n            }\n        }\n    }\n\n    \n    softmax(attention);\n\n    \n    for (int b = 0; b < B; ++b) {\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < dv; ++j) {\n                float sum = 0;\n                for (int k = 0; k < N; ++k) {\n                    sum += attention[b][i][k] * V[b][k][j].to_float();\n                }\n                Output[b][i][j] = (fixed_t)sum;\n            }\n        }\n    }\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "compute_attention_HLS"
  },
  {
    "input": "This is an unsynthesizable C code:\nslow code Version:\n\n```cpp\n#include <string.h>\n#define INT_MAX 100000\n#include <stdlib.h>\nstatic void short_path_kernel(\n    const int *rpao, \n    const int *ciao, \n    const int *weights, \n    int *distance, \n    const int vertex_num, \n    const int src\n) {\n    for (int i = 0; i < vertex_num; i++) {\n        distance[i] = INT_MAX;\n    }\n    distance[src] = 0;\n\n    int *visited = static_cast<int*>(std::calloc(vertex_num, sizeof(int)));\n\n    for (int i = 0; i < vertex_num - 1; i++) {\n        int min_dis = INT_MAX;\n        int min_idx = -1;\n\n        for (int j = 0; j < vertex_num; j++) {\n            if (!visited[j] && distance[j] < min_dis) {\n                min_dis = distance[j];\n                min_idx = j;\n            }\n        }\n\n        visited[min_idx] = true;\n\n        int start = rpao[min_idx];\n        int end = rpao[min_idx + 1];\n\n        for (int j = start; j < end; j++) {\n            int ngb_idx = ciao[j];\n            int weight = weights[j];\n            int new_dis = distance[min_idx] + weight;\n\n            if (new_dis < distance[ngb_idx]) {\n                distance[ngb_idx] = new_dis;\n            }\n        }\n    }\n}\n\n\nvoid short_path(\n        const int *rpao, \n        const int *ciao, \n        const int *weights, \n        int *distance, \n        const int vertex_num, \n        const int src\n    ) {\n#pragma HLS INTERFACE m_axi port=rpao offset=slave bundle=gmem0\n#pragma HLS INTERFACE m_axi port=ciao offset=slave bundle=gmem1\n#pragma HLS INTERFACE m_axi port=weights offset=slave bundle=gmem2\n#pragma HLS INTERFACE m_axi port=distance offset=slave bundle=gmem3\n#pragma HLS INTERFACE s_axilite port=rpao bundle=control\n#pragma HLS INTERFACE s_axilite port=ciao bundle=control\n#pragma HLS INTERFACE s_axilite port=weights bundle=control\n#pragma HLS INTERFACE s_axilite port=distance bundle=control\n#pragma HLS INTERFACE s_axilite port=vertex_num bundle=control\n#pragma HLS INTERFACE s_axilite port=src bundle=control\n#pragma HLS INTERFACE s_axilite port=return bundle=control\n\n        short_path_kernel(rpao, ciao, weights, distance, vertex_num, src);\n\n}\n```\nWe want to turn it into synthesizable C code. Just give me the HLS code.",
    "app": "shortpath"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\n#include \"sparse_matrix_multiply_HLS.h\"\n\ntypedef ap_fixed<16, 5> data_t;\n\n#define N 64  \n#define M 64  \n#define K 64  \n\nvoid sparse_matrix_multiply_HLS(data_t values_A[N * M],\n                              int column_indices_A[N * M],\n                              int row_ptr_A[N + 1],\n                              data_t values_B[M * K],\n                              int row_indices_B[M * K],\n                              int col_ptr_B[M + 1],\n                              data_t C[N][K]) \n{\n    data_t local_values_A[N * M];\n    int   local_column_indices_A[N * M];\n    int   local_row_ptr_A[N + 1];\n\n    data_t local_values_B[M * K];\n    int   local_row_indices_B[M * K];\n    int   local_col_ptr_B[M + 1];\n\n    data_t accum[N][K];\n\n    \n    for (int i = 0; i < N + 1; i++) {\n        local_row_ptr_A[i] = row_ptr_A[i];\n    }\n    int nnzA = row_ptr_A[N];\n    for (int i = 0; i < nnzA; i++) {\n        #pragma HLS loop_tripcount min= 1  max=256\n        local_values_A[i]        = values_A[i];\n        local_column_indices_A[i] = column_indices_A[i];\n    }\n\n    \n    for (int i = 0; i < M + 1; i++) {\n        local_col_ptr_B[i] = col_ptr_B[i];\n    }\n    int nnzB = col_ptr_B[M];\n    for (int i = 0; i < nnzB; i++) {\n        #pragma HLS loop_tripcount min= 1  max=256\n        local_values_B[i]      = values_B[i];\n        local_row_indices_B[i] = row_indices_B[i];\n    }\n\n    \n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < K; j++) {\n            accum[i][j] = (data_t)0;\n        }\n    }\n\n    \n    for (int i = 0; i < N; i++) {\n        int startA = local_row_ptr_A[i];\n        int endA   = local_row_ptr_A[i + 1];\n        for (int a = startA; a < endA; a++) {\n            #pragma HLS loop_tripcount min= 1  max=256\n            data_t a_val = local_values_A[a];\n            int    col   = local_column_indices_A[a];\n            int    startB = local_col_ptr_B[col];\n            int    endB   = local_col_ptr_B[col + 1];\n            for (int b = startB; b < endB; b++) {\n                #pragma HLS loop_tripcount min= 1  max=256\n                data_t b_val = local_values_B[b];\n                int    row   = local_row_indices_B[b];\n                accum[i][row] += a_val * b_val;\n            }\n        }\n    }\n\n    \n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < K; j++) {\n            C[i][j] = accum[i][j];\n        }\n    }\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "sparse_matrix_multiply_HLS"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\n#define MAX_NODES 2000\n#define MAX_EDGES 1000\n#define DEGREE_GUESS 200\n\nvoid gather_node_neighbors(\n    int node,\n    int node_in_degree,\n    int node_neighbors[MAX_NODES],\n    int neighbor_table_offsets[MAX_NODES],\n    int neighbor_table[MAX_EDGES]) {\n\n#pragma HLS INLINE off\n    \n\n    int node_offset = neighbor_table_offsets[node];\n    for (int i = 0; i < node_in_degree; i++) {\n#pragma HLS loop_tripcount min = 1 max = DEGREE_GUESS\n        int current_idx = node_offset + i;\n        node_neighbors[i] = neighbor_table[current_idx];\n    }\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "gather_node_neighbors"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\n#define NUM_TRAINING 18000\n#define CLASS_SIZE 1800\n#define NUM_TEST 2000\n#define DIGIT_WIDTH 4\n\n\ntypedef unsigned long long DigitType;\ntypedef unsigned char      LabelType;\n\n\n#define K_CONST 3\n#define PAR_FACTOR 40\n\nconst unsigned long long m1  = 0x5555555555555555; \nconst unsigned long long m2  = 0x3333333333333333; \nconst unsigned long long m4  = 0x0f0f0f0f0f0f0f0f; \n\n\n\nint popcount(DigitType x)\n{\n   x -= (x >> 1) & m1;             \n   x = (x & m2) + ((x >> 2) & m2); \n   x = (x + (x >> 4)) & m4;        \n   x += x >>  8;  \n   x += x >> 16;  \n   x += x >> 32;  \n   return x & 0x7f;\n}\n\nvoid update_knn( const DigitType* train_inst, const DigitType* test_inst, int dists[K_CONST], int labels[K_CONST], int label ) \n{\n  int dist = 0;\n\n  for (int i = 0; i < DIGIT_WIDTH; i ++ )\n  {\n    DigitType diff = test_inst[i] ^ train_inst[i];\n    dist += popcount(diff);\n  }\n\n  int max_dist = 0;\n  int max_dist_id = K_CONST+1;\n\n  \n  FIND_MAX_DIST: for ( int k = 0; k < K_CONST; ++k ) \n  {\n    if ( dists[k] > max_dist ) \n    {\n      max_dist = dists[k];\n      max_dist_id = k;\n    }\n  }\n\n  \n  if ( dist < max_dist )\n  {\n    dists[max_dist_id] = dist;\n    labels[max_dist_id] = label;\n  }\n\n  return;\n}\n\nLabelType knn_vote(int labels[K_CONST]) \n{\n  int max_vote = 0;\n  LabelType max_label = 0;\n  \n  int votes[10] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0};\n\n  for (int i = 0; i < K_CONST; i ++ )\n    votes[labels[i]] ++;\n\n  for (int i = 0; i < 10; i ++ ) \n  {\n    if (votes[i] > max_vote)\n    {\n      max_vote = votes[i];\n      max_label = i;\n    }\n  }\n\n  return max_label;\n\n}\n\n\n\nvoid spam_filter(const DigitType training_set[NUM_TRAINING * DIGIT_WIDTH], \n                 const DigitType test_set[NUM_TEST * DIGIT_WIDTH], \n                 LabelType results[NUM_TEST]) \n{\n\n  \n  int dists[K_CONST];\n  int labels[K_CONST];\n\n  \n  TEST_LOOP: for (int t = 0; t < NUM_TEST; ++t) \n  {\n    \n    SET_KNN_SET: for ( int i = 0; i < K_CONST; ++i ) \n    {\n      \n      dists[i] = 256;\n      labels[i] = 0;\n    }\n\n    \n    TRAINING_LOOP : for ( int i = 0; i < NUM_TRAINING; ++i ) \n      update_knn(&training_set[i * DIGIT_WIDTH], &test_set[t * DIGIT_WIDTH], dists, labels, i / CLASS_SIZE);\n      \n    \n    LabelType max_vote = knn_vote(labels);\n    results[t] = max_vote;\n\n  }\n\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "spam_filter"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\n#define BATCH_SIZE_1 262144\n#define INTERNAL_BATCH_SIZE 4096\n#define INTERNAL_BATCHES 64\n\n\n\n#include \"ap_fixed.h\"\n\n#define DEC_BITS 6\n#define INT_BITS 13\n\ntypedef ap_fixed<INT_BITS + DEC_BITS, INT_BITS, AP_RND> DTYPE;\n\n\n\n#include \"ap_int.h\"\n\n#define WIDTH 256\n#define FLOAT_BITS (sizeof(float) * 8)\n#define FLOATS_PER_ELEMENT (WIDTH / FLOAT_BITS)\n\ntypedef ap_uint<WIDTH> INTERFACE_WIDTH;\n\ntypedef union\n{\n\tint raw_val;\n\tfloat float_val;\n} raw_float;\n\nextern \"C\"{\n\n\tvoid kalman_filter(INTERFACE_WIDTH in[BATCH_SIZE_1 / FLOATS_PER_ELEMENT], INTERFACE_WIDTH out[BATCH_SIZE_1 / FLOATS_PER_ELEMENT]) {\n\t\t#pragma HLS INTERFACE m_axi port=in bundle=gmem0\n\t\t#pragma HLS INTERFACE m_axi port=out bundle=gmem1\n\n\t\tDTYPE in_local[BATCH_SIZE_1];\n\t\tDTYPE out_local[BATCH_SIZE_1];\n\n\t\tINTERFACE_WIDTH temp;\n\t\tint counter = 0;\n\t\tfor(int i = 0; i < BATCH_SIZE_1 / FLOATS_PER_ELEMENT; i++) {\n\t\t\ttemp = in[i];\n\n\t\t\tfor(int j = 0; j < FLOATS_PER_ELEMENT; j++) {\n\t\t\t\traw_float t;\n\t\t\t        t.raw_val = temp.range((j + 1) * FLOAT_BITS - 1, j * FLOAT_BITS);\n\t\t\t        in_local[counter] = (DTYPE)t.float_val;\n\n\t\t\t\tcounter++;\n\t\t\t}\n\t\t}\n\n\t\tDTYPE u_hat_arr[INTERNAL_BATCHES];\n\t\tDTYPE p_arr_1[INTERNAL_BATCHES];\n\t\tDTYPE k_arr[INTERNAL_BATCHES];\n\t\tDTYPE calc_temp_arr[INTERNAL_BATCHES];\n\n\t\tfor (int i = 0; i < INTERNAL_BATCHES; i++) {\n\t\t\tu_hat_arr[i] = in_local[i * INTERNAL_BATCH_SIZE];\n\t\t\tp_arr_1[i] = 0.5;\n\t\t\tout_local[i * INTERNAL_BATCH_SIZE] = u_hat_arr[i];\n\t\t}\n\n\t\tfor (int t = 1; t < INTERNAL_BATCH_SIZE; t++) {\n\t\t\tfor (int i = 0; i < INTERNAL_BATCHES; i++) {\n\t\t\t\tcalc_temp_arr[i] = p_arr_1[i] + (DTYPE)0.01;\n\n\t\t\t\tk_arr[i] = calc_temp_arr[i] / (p_arr_1[i] + (DTYPE)1.01);\n\t\t\t\t\n\t\t\t\tu_hat_arr[i] = u_hat_arr[i] + k_arr[i] * (in_local[i * INTERNAL_BATCH_SIZE + t] - u_hat_arr[i]);\n\t\t\t\t\n\t\t\t\tp_arr_1[i] = ((DTYPE)1 - k_arr[i]) * calc_temp_arr[i];\n\t\t\t\t\n\t\t\t\tout_local[i * INTERNAL_BATCH_SIZE + t] = u_hat_arr[i];\n\t\t\t}\n\t\t}\n\n\t\tcounter = 0;\n\t\tfor(int i = 0; i < BATCH_SIZE_1 / FLOATS_PER_ELEMENT; i++) {\n\t\t\ttemp = 0;\n\n\t\tfor(int j = 0; j < FLOATS_PER_ELEMENT; j++) {\n\t\t\t\traw_float t;\n\t\t\t\tt.float_val = (float)out_local[counter];\n\n \t\t\t\ttemp.range((j + 1) * FLOAT_BITS - 1, j * FLOAT_BITS) = t.raw_val;\n\n\t\t\t\tcounter++;\n\t\t\t}\n\n\t\t\tout[i] = temp;\n\t\t}\n\t}\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "kalman_filter"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\n#include <stdio.h>\n#include <math.h>\n#include <stdlib.h>\n\n#define WIDTH 64\n#define HEIGHT 64\n\n\nvoid edge_detect(int *inputImage, int *outputImage,int EDGE_THRESHOLD) {\n#pragma HLS INTERFACE m_axi depth=4096 port=outputImage offset=slave bundle=out\n#pragma HLS INTERFACE m_axi depth=4096 port=inputImage offset=slave bundle=in\n\n\n\tint image_data[WIDTH+2][WIDTH+2];\nIMG_CREATE:\n    for(int p = 0 ; p < WIDTH+2 ; p++){\n        for(int q = 0 ; q < WIDTH +2 ; q++){\n            if( p ==0 || q ==0 || p ==WIDTH+1 || q ==WIDTH+1)\n                image_data[p][q]=0;\n            else\n                image_data[p][q] = inputImage[(q-1)+(p-1)*WIDTH];\n            }\n    }\n\n    int Gx[WIDTH][WIDTH];\n    int Gy[WIDTH][WIDTH];\nOUTPUT_CREATE:\n    for(int i = 1 ; i < WIDTH+1 ; i++){\n        for(int j = 1 ; j < WIDTH+1 ; j++){\n            Gx[i-1][j-1] = (image_data[i-1][j-1] + 2* image_data[i-1][j] + image_data[i-1][j+1]) - (image_data[i+1][j-1] + 2* image_data[i+1][j] + image_data[i+1][j+1]);\n            Gy[i-1][j-1] = (image_data[i-1][j-1] + 2* image_data[i][j-1] + image_data[i+1][j-1]) - (image_data[i-1][j+1] + 2* image_data[i][j+1] + image_data[i+1][j+1]);\n            int gradient = (int)sqrt(Gx[i-1][j-1] * Gx[i-1][j-1] + Gy[i-1][j-1] * Gy[i-1][j-1]);\n            if (gradient > EDGE_THRESHOLD) {\n                outputImage[(j-1)+WIDTH*(i-1)] = 255;  \n            } else {\n                outputImage[(j-1)+WIDTH*(i-1)] = 0;    \n            }\n        }\n    }\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "edge_detect"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\n#include <cmath>\n#include <limits>\n#include <stdio.h>\n\n#define TARGETS 3000\n#define QUERIES 1000\n#define DIMS 3\n\nfloat compute_distance(float target[DIMS], float query[DIMS]) {\n    float dist = 0.0f;\n    for (int i = 0; i < DIMS; i++) {\n        float diff = target[i] - query[i];\n        dist += diff * diff;\n    }\n    return dist;\n}\n\nvoid queries_search(float* targets, float* queries, unsigned int indices[QUERIES]) {\n    for (int q = 0; q < QUERIES; q++) {\n        float min_dist = std::numeric_limits<float>::max();\n        unsigned int min_index = 0;\n        \n        for (int t = 0; t < TARGETS; t++) {\n            float dist = compute_distance(targets, queries);\n            if (dist < min_dist) {\n                min_dist = dist;\n                min_index = t;\n            }\n        }\n        \n        indices[q] = min_index;\n    }\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "queries_search"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\n#include \"ap_fixed.h\"\n\ntypedef unsigned int UINTYPE_12;\ntypedef ap_fixed<12, 2> THETA_TYPE;\ntypedef ap_fixed<12, 2> COS_SIN_TYPE;\nconst int NUM_ITERATIONS = 32;\n\nconst int NUM_DEGREE = 90;\nstatic THETA_TYPE cordic_phase[64] = {\n    0.78539816339744828000, 0.46364760900080609000, 0.24497866312686414000,\n    0.12435499454676144000, 0.06241880999595735000, 0.03123983343026827700,\n    0.01562372862047683100, 0.00781234106010111110, 0.00390623013196697180,\n    0.00195312251647881880, 0.00097656218955931946, 0.00048828121119489829,\n    0.00024414062014936177, 0.00012207031189367021, 0.00006103515617420877,\n    0.00003051757811552610, 0.00001525878906131576, 0.00000762939453110197,\n    0.00000381469726560650, 0.00000190734863281019, 0.00000095367431640596,\n    0.00000047683715820309, 0.00000023841857910156, 0.00000011920928955078,\n    0.00000005960464477539, 0.00000002980232238770, 0.00000001490116119385,\n    0.00000000745058059692, 0.00000000372529029846, 0.00000000186264514923,\n    0.00000000093132257462, 0.00000000046566128731, 0.00000000023283064365,\n    0.00000000011641532183, 0.00000000005820766091, 0.00000000002910383046,\n    0.00000000001455191523, 0.00000000000727595761, 0.00000000000363797881,\n    0.00000000000181898940, 0.00000000000090949470, 0.00000000000045474735,\n    0.00000000000022737368, 0.00000000000011368684, 0.00000000000005684342,\n    0.00000000000002842171, 0.00000000000001421085, 0.00000000000000710543,\n    0.00000000000000355271, 0.00000000000000177636, 0.00000000000000088818,\n    0.00000000000000044409, 0.00000000000000022204, 0.00000000000000011102,\n    0.00000000000000005551, 0.00000000000000002776, 0.00000000000000001388,\n    0.00000000000000000694, 0.00000000000000000347, 0.00000000000000000173,\n    0.00000000000000000087, 0.00000000000000000043, 0.00000000000000000022,\n    0.00000000000000000011};\n\nvoid cordic(THETA_TYPE theta, COS_SIN_TYPE &s, COS_SIN_TYPE &c) {\n    \n    \n    COS_SIN_TYPE current_cos = 0.60735;\n    COS_SIN_TYPE current_sin = 0.0;\n\n    COS_SIN_TYPE factor = 1.0;\n    \n    \n    for (int j = 0; j < NUM_ITERATIONS; j++) {\n        \n        int sigma = (theta < 0) ? -1 : 1;\n\n        \n        COS_SIN_TYPE cos_shift = current_cos * sigma * factor;\n        COS_SIN_TYPE sin_shift = current_sin * sigma * factor;\n\n        \n        current_cos = current_cos - sin_shift;\n        current_sin = current_sin + cos_shift;\n\n        \n        theta = theta - sigma * cordic_phase[j];\n\n        factor = factor / 2;\n    }\n\n    \n    s = current_sin;\n    c = current_cos;\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "cordic"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\n#define MAX_NODES 100\n#define MAX_EDGES 1000\n#define NUM_NODES_GUESS 50\n#define NUM_EDGES_GUESS 500\n\nvoid compute_neighbor_tables(\n    int edge_list[MAX_EDGES][2],\n    int in_degree_table[MAX_NODES],\n    int out_degree_table[MAX_NODES],\n    int neighbor_table_offsets[MAX_NODES],\n    int neighbor_table[MAX_EDGES],\n    int num_nodes,\n    int num_edges) {\n\n\n    int neightbor_table_offsets_temp[MAX_NODES];\n    neighbor_table_offsets[0] = 0;\n    neightbor_table_offsets_temp[0] = 0;\n    for (int i = 1; i < num_nodes; i++) {\n#pragma HLS loop_tripcount min = 1 max = NUM_NODES_GUESS\n        int csum = neighbor_table_offsets[i - 1] + in_degree_table[i - 1];\n        neighbor_table_offsets[i] = csum;\n        neightbor_table_offsets_temp[i] = csum;\n    }\n\n    \n    for (int i = 0; i < num_edges; i++) {\n#pragma HLS loop_tripcount min = 1 max = NUM_EDGES_GUESS\n        int source = edge_list[i][0];\n        int dest = edge_list[i][1];\n\n        int offset = neightbor_table_offsets_temp[dest];\n        neighbor_table[offset] = source;\n        neightbor_table_offsets_temp[dest]++;\n    }\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "compute_neighbor_tables"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\n#include <iomanip>\n#include <iostream>\n#include <vector>\nusing namespace std;\n\n#include \"hls_stream.h\"\n\ntypedef int DTYPE;\nconst int SIZE = 8;\nconst int BLOCK_SIZE = 4;\n\ntypedef struct {\n    DTYPE a[BLOCK_SIZE];\n} blockvec;\n\ntypedef struct {\n    DTYPE out[BLOCK_SIZE][BLOCK_SIZE];\n} blockmat;\n\nvoid block_mm(hls::stream<blockvec> &Arows, hls::stream<blockvec> &Bcols,\n        blockmat &ABpartial, int it) {\n  int counter = it % (SIZE/BLOCK_SIZE);\n  static DTYPE A[BLOCK_SIZE][SIZE];\n  if(counter == 0){ \n    loadA: for(int i = 0; i < SIZE; i++) {\n      blockvec tempA = Arows.read();\n      for(int j = 0; j < BLOCK_SIZE; j++) {\n        A[j][i] = tempA.a[j];\n      }\n    }\n  }\n  DTYPE AB[BLOCK_SIZE][BLOCK_SIZE] = { 0 };\n  partialsum: for(int k=0; k < SIZE; k++) {\n    blockvec tempB = Bcols.read();\n    for(int i = 0; i < BLOCK_SIZE; i++) {\n      for(int j = 0; j < BLOCK_SIZE; j++) {\n        AB[i][j] = AB[i][j] +  A[i][k] * tempB.a[j];\n      }\n    }\n  }\n  writeoutput: for(int i = 0; i < BLOCK_SIZE; i++) {\n    for(int j = 0; j < BLOCK_SIZE; j++) {\n      ABpartial.out[i][j] = AB[i][j];\n    }\n  }\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "block_mm"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\nconst int NUM_FEATURE = 2;\nconst int NUM_PT_IN_SEARCHSPACE = 1024*1024;\nconst int NUM_PT_IN_BUFFER = 512;\nconst int NUM_TILES = NUM_PT_IN_SEARCHSPACE / NUM_PT_IN_BUFFER;\nconst int UNROLL_FACTOR = 2;\nconst int DWIDTH = 512;\n#define INTERFACE_WIDTH ap_uint<DWIDTH>\nconst int WIDTH_FACTOR = DWIDTH/32;\n \nextern \"C\"{\nvoid compute_near(\n    float inputQuery[NUM_FEATURE],\n    float searchSpace[NUM_PT_IN_SEARCHSPACE*NUM_FEATURE],\n    float distance[NUM_PT_IN_SEARCHSPACE]\n){\n    #pragma HLS INTERFACE m_axi port=inputQuery offset=slave bundle=gmem\n    #pragma HLS INTERFACE s_axilite port=inputQuery bundle=control\n    #pragma HLS INTERFACE m_axi port=searchSpace offset=slave bundle=gmem\n    #pragma HLS INTERFACE s_axilite port=searchSpace bundle=control\n    #pragma HLS INTERFACE m_axi port=distance offset=slave bundle=gmem\n    #pragma HLS INTERFACE s_axilite port=distance bundle=control\n    #pragma HLS INTERFACE s_axilite port=return bundle=control\n    \n    float sum;\n    float feature_delta;\nL1:    for(int i = 0; i < NUM_PT_IN_SEARCHSPACE; ++i){\n        sum = 0.0;\nL2:        for(int j = 0; j < NUM_FEATURE; ++j){\n            feature_delta = searchSpace[i*NUM_FEATURE+j] - inputQuery[j];\n            sum += feature_delta*feature_delta;\n        }\n        distance[i] = sum;\n    }\n\n    return;\n}\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "compute_near"
  },
  {
    "input": "This is a slow high level synthesis (HLS) FPGA program:\nslow code Version:\n\n```cpp\n#include <stdio.h>\n#include <math.h>\n#define gamma 8\n#define b 0\n#define N_FEATURES 1248\n#define N_SUP_VECT 18\n\nconst float sv_coeff[N_FEATURES] = {1, 2, 2, 1};\nconst float sup_vectors[N_SUP_VECT][N_FEATURES] = {{1, 5, 2.2, 1.1}, {1, 2, 4, 1.1}, {1, 2.1, 2.2, 1.1}, {1, 8, 2.2, 1.1}};\n\nint svm(float test_vector[N_SUP_VECT])\n{\n    float diff;\n    float norma;\n    int sum = 0;\n    for (int i = 0; i < N_FEATURES; i++)\n    {\n        for (int j = 0; j < N_SUP_VECT; j++)\n        {\n            diff = test_vector[j] - sup_vectors[j][i];\n            diff = diff * diff;\n            norma = norma + diff;\n        }\n        sum = sum + (exp(-gamma * norma) * sv_coeff[i]);\n        norma = 0;\n    }\n    sum = sum - b;\n    return sum;\n}\n```\nWe want to optimize its performance with fewer resources. The ports of top function can not be changed. Just give me the optimized HLS code.",
    "app": "svm"
  },
  {
    "input": "According to the opt description This code defines a hardware-implemented grouped 2D convolution layer with Tanh activation using 16-bit fixed-point arithmetic. Key parameters:\n\n1. **Layer Configuration**\n   - Input: 32 channels × 28×56 (CIN32_HIN28_WIN56)\n   - Output: 32 channels × 30×58 (COUT32 with padding PAD1)\n   - 1×1 kernel (K1) with stride 1, no bias (BIASFalse)\n\n2. **Hardware Optimization**\n   - Uses unrolling factors: UFCIN1 (input channels) and UFCOU4 (output channels)\n   - Fixed-point type: ap_fixed<16,5> for all tensors\n   - Group convolution implementation (group_conv2d)\n\n3. **Data Flow**\n   - Processes DRAM_image_input through:\n     1. Convolution with 32×32×1×1 weights\n     2. Batch normalization using 4 parameters per channel\n     3. Tanh activation\n   - Stores result in DRAM_image_output\n\nThe implementation emphasizes spatial preservation through padding (PAD1) while maintaining channel dimensions, typical for depthwise-separable convolution variants in hardware-efficient designs. and simple C code #include <math.h>\n\nvoid top(float* DRAM_image_input, float* DRAM_conv_weight, float* DRAM_conv_bias,\n         float* DRAM_batch_norm_weights, float* DRAM_image_output) {\n\n    const int C_IN = 32, H_IN = 28, W_IN = 56;\n    const int C_OUT = 32, H_OUT = 30, W_OUT = 58;\n\n    for (int co = 0; co < C_OUT; ++co) {\n        float gamma = DRAM_batch_norm_weights[0*32 + co];\n        float beta = DRAM_batch_norm_weights[1*32 + co];\n        float mean = DRAM_batch_norm_weights[2*32 + co];\n        float var = DRAM_batch_norm_weights[3*32 + co];\n\n        for (int h = 0; h < H_OUT; ++h) {\n            for (int w = 0; w < W_OUT; ++w) {\n                float sum = DRAM_conv_bias[co];\n\n                for (int ci = 0; ci < C_IN; ++ci) {\n                    int inp_h = h - 1, inp_w = w - 1;\n                    float val = 0.0f;\n                    \n                    if (inp_h >= 0 && inp_h < H_IN && inp_w >= 0 && inp_w < W_IN) {\n                        val = DRAM_image_input[ci*H_IN*W_IN + inp_h*W_IN + inp_w];\n                    }\n                    \n                    sum += val * DRAM_conv_weight[co*C_IN + ci];\n                }\n\n                // Batch normalization\n                float eps = 1e-5f;\n                float norm = (sum - mean) / sqrtf(var + eps) * gamma + beta;\n                \n                // sigmoid activation\n                DRAM_image_output[co*H_OUT*W_OUT + h*W_OUT + w] = norm > 0 ? norm : 0;\n            }\n        }\n    }\n}, to generate Xilinx FPGA High level synthesis code: ",
    "app": "dnn"
  },
  {
    "input": "According to the opt description This code implements a fixed-point GEMM (General Matrix Multiply) operation with configuration M=128, K=64, N=128, using 16-bit fixed-point numbers (5 integer bits, 11 fractional bits). It features:\n\n1. **Matrix Dimensions**  \n   - Input matrix A: 128×64  \n   - Input matrix B: 64×128  \n   - Output matrix: 128×128 (implied by M/N, though result storage appears incomplete in code)\n\n2. **Optimizations**  \n   - Loop unrolling factors: K-dimension unrolled 8× (UK8)  \n   - Loop order: `ikj`  \n   - Function inlining enabled  \n\n3. **Data Types**  \n   - Uses `ap_fixed<16,5>` for all operands  \n   - Explicitly disables bias addition (`BIAS_False`)  \n\n4. **Interface**  \n   - Accepts inputs from DRAM (arrays)  \n   - Includes a placeholder single-element bias input (unused)  \n   - Outputs to a single-element array (likely incomplete/placeholder implementation)  \n\nThe code appears to be a hardware-oriented implementation (HLS) with memory access patterns and fixed-point precision optimized for FPGA/ASIC deployment. and simple C code #include <stdio.h>\n\nvoid top(float DRAM_x[128], float DRAM_A[128][64], float DRAM_B[64][128], \n        float DRAM_y[128], float DRAM_bias[1], float DRAM_result[1]) {\n    \n    // Matrix multiplication: B (64x128) * x (128x1)\n    float Bx[64] = {0};\n    for(int i = 0; i < 64; i++) {\n        for(int j = 0; j < 128; j++) {\n            Bx[i] += DRAM_B[i][j] * DRAM_x[j];\n        }\n    }\n    \n    // Matrix multiplication: A (128x64) * Bx (64x1)\n    float ABx[128] = {0};\n    for(int i = 0; i < 128; i++) {\n        for(int j = 0; j < 64; j++) {\n            ABx[i] += DRAM_A[i][j] * Bx[j];\n        }\n    }\n    \n    // Add bias and apply ReLU activation\n    float sum = 0;\n    for(int i = 0; i < 128; i++) {\n        float val = ABx[i] + DRAM_bias[0];\n        DRAM_y[i] = val > 0 ? val : 0;  // ReLU\n        sum += DRAM_y[i];\n    }\n    \n    // Final result aggregation\n    DRAM_result[0] = sum;\n}, to generate Xilinx FPGA High level synthesis code: ",
    "app": "gemm"
  }
]